---
title: "Modelling the effect of interventions on COVID-19 in Victoria"
subtitle: ETC5512 Assignment 4, Master of Business Analytics
bibliography: references.bib
author: Arindom Baruah, 32779267, abar0090@student.monash.edu
date: '`r Sys.Date()`'
output:
  bookdown::html_document2:
    biblio-style: "apalike"
    link-citations: true
    css: monashreport.css
    includes:
      before_body: header.html
---

```{css, echo=FALSE}
.watch-out {
  background-color: lightgray;
  border: 3px solid black;
  font-weight: bold;
  
}
```



```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  class.source='watch-out'
)
```




```{r libraries}
library(tidyverse)
library(here)
library(ggplot2)
library(ggthemes)
library(bookdown)
library(stringr)
library(DT)
library(kableExtra)
library(deSolve)
```



```{r data_sourcing}
df <- read_csv(here::here("data/NCOV_cases_by_postcode_LGA.csv"))
```

# Data sources

1. The dataset pertaining to the COVID-19 cases for the current study is obtained from the official data source of COVID-19 cases curated by the [Victorian Government](https://www.coronavirus.vic.gov.au). This particular dataset contains all the reported cases in the state of Victoria between the time period of January 2020 to June 2022 and can be found in the __[data download](https://www.coronavirus.vic.gov.au/victorian-coronavirus-covid-19-data)__ section. The dataset contains the __diagnosis date, geographical origin of the infection case and the number of cases observed for the particular day__. Moreover, the dataset has a __long format__ which aids the __temporal analysis and modeling__ that will be carried out in the current study. Due to the __authenticity of the dataset__ due to it being released by the Victorian Government directly as well as the __tidy format of the data__, this dataset is ideal for the current analysis.

2. The COVID-19 cases dataset released by Victorian Government is a type of __observational dataset__ as:

   - The dataset contains observations of COVID-19 incidences observed over a period of time in the state of Victoria.
   - The independent variables in the dataset are __not artificially or intentionally placed in specific units__ for the purpose of a study.
   - There is no scenario where only a specific group of people who are exposed to the virus are studied against the rest of the people who are not exposed to the virus which would have suggested an experimental data.
   - There is __no certain scientific claim__ that is expected to be validated using this dataset, as is usually the case for experimental data.
 
3. Codebook for the current dataset can be referred to in the submitted list of files __within the "data" folder__.
   
4. The unit of this current dataset is __the number of positive diagnosed cases__. This unit represents the number of confirmed COVID-19 cases in a particular geographical region or time frame. It contains daily positive cases broken down into the __type of COVID test, data of diagnosis and the geographical region where the case was detected__.
Some of the variables which could act as unique identifiers for the COVID-19 dataset are __diagnosis data,age group,post code and the total case count__. For the days with a single observed case in any of the locations (postal code) and age group, a person maybe uniquely identified. 

5. The Victorian Government website contains the COVID-19 information on the number of cases for each local government area and age groups as __separate datasets__. Ideally, we would want the __geographical data to be stored within one single dataset__ so that we can analyse where were the restrictions enforced and who were affected by these restrictions.

The current dataset is clean and is in the required long format to perform exploratory data analysis for a time-series. Moreover, there are no null values observed in the dataset which aids in the analysis as we are not required to perform any further data cleaning steps.

However, the __variable name "Total_case_count" can be misleading__ as it does not specify whether the number of cases __are for one day__ or __the cumulative number of cases__ since the start of analysis.

Overall, it can be concluded that the dataset is __adequately prepared for storage and usage__.

Following were the data wrangling steps applied to obtain the finalized dataset:

- Dataset of COVID-19 cases were __granulated by local government areas__ was considered for creation of the required dataset.
- The total case count was grouped by the diagnosis date and summarised as the total number of cases for each date.
- Summarisation of the dataframe removed the unwanted fields such as lga code, lga name and the case counts by type of test.
- Perform a join between the local government area and the agegroup dataset on the diagnosis date.
- In order to calculate the __7-day growth rate__, a slider function was utilised to calculate the growth rate of total positive cases per day on the __log scale__.

Table \@ref(tab:datasetjoin) illustrates the new dataset created after joining the two dataframes.

```{r datasetjoin}


head(df) %>%
kable(caption = 'Mean economic statistics of Melbourne electorate based on 2021 Census data',booktabs = TRUE) %>% 
  kable_styling(bootstrap_options = c("bordered","hover")) %>%
  row_spec(0,background="rgb(172,175,145)",color='black',font_size = 18,align = 'c')


```



# üîç Analysis

## <u> Daily cases observed </u>

```{r caseplot, fig.cap="Cases observed per day",fig.align='center',include=TRUE}

start_date <- ymd("2020/06/01") #Start date of analysis
end_date <- ymd("2020/09/13") #End date of analysis
local_ld <- ymd("2020/06/30") #Local lockdown initiates
face_mask <- ymd("2020/07/27") # Mandatory facemasks

plot_interval <- interval(start_date, end_date)


df_daily <- df %>% filter(diagnosis_date %within% plot_interval) %>% group_by(diagnosis_date)  %>% summarise(Cases_per_day = sum(Total_case_count))


pl1 <- ggplot(data = df_daily,
              aes(x = diagnosis_date,
                  y = Cases_per_day)) +
  geom_line() + theme_clean() +
  labs(x = "Diagnosis date", y = " Total cases per day") +
  ggtitle("Cases observed per day in 2020") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.title = element_text(face = 'bold')) +
  annotate("segment",x = local_ld,
    xend = local_ld,y = 0,
    yend = 700,colour = "red",
    linetype = 1,size = 2
  ) +
  annotate("segment",x = local_ld - days(6),
    y = 500,xend = local_ld ,
    yend = 400 ,arrow = arrow(type = "closed", 
                              length = unit(0.02, "npc"))
  ) +
  annotate("text",x = local_ld - days(15),
    y = 520,colour = "black",
    label = 'Lockdowns implemented \n from 30/06/2020',size = unit(3, "pt")
  ) +
  annotate("segment",x = face_mask,
    xend = face_mask,y = 0,
    yend = 700,colour = "blue",
    linetype = 1,size = 2
  ) +
  annotate("segment",x = face_mask - days(6),
    y = 500,xend = face_mask ,
    yend = 400 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))
  ) +
  annotate("text",x = face_mask - days(12),
    y = 530,colour = "black",
    label = 'Mandatory facemasks \n from 27/07/2020',size = unit(3, "pt")
  )
pl1


```


```{r avgratecalc}
df_rate <- df_daily %>%
  mutate(
    growth_rate = slider::slide_dbl(
      .x = Cases_per_day,
      .f = mean,
      .before = 6,
      .after = 0
    )
  )
```

```{r avgrateplot,fig.cap="7-day average rise of cases observed per day",fig.align='center',include=TRUE }

pl2 <- ggplot(data = df_rate,
              aes(x = diagnosis_date,
                  y = growth_rate)) +
  geom_line(size=1.5) + theme_clean() +
  labs(x = "Diagnosis date", y = "Total cases per day") +
  ggtitle("7-day rolling average of cases per day \n in 2020") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.title = element_text(face = 'bold')) +
  annotate("segment",x = local_ld,
    xend = local_ld,y = 0,
    yend = 700,colour = "red",
    linetype = 1,size = 2) +
  annotate("segment",x = local_ld - days(6),
    y = 500,xend = local_ld ,
    yend = 400 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = local_ld - days(15),y = 520,
    colour = "black",label = 'Lockdowns implemented \n from 30/06/2020',size = unit(3, "pt")) +
  annotate("segment",x = face_mask,xend = face_mask,
    y = 0,yend = 700,colour = "blue",linetype = 1,size = 2) +
  annotate("segment",x = face_mask - days(6),y = 500,
    xend = face_mask ,yend = 400 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = face_mask - days(12),y = 530,colour = "black",
    label = 'Mandatory facemasks \n from 27/07/2020',
    size = unit(3, "pt")
  )
pl2

```
As we can observe,the primary difference between the figures \@ref(fig:caseplot) and \@ref(fig:avgrateplot) is the smoothness of the lineplot. As we are using a 7-day mean growth rate instead of the actual daily cases, __the sudden spikes in the number of cases as a result of the peaks and troughs were greatly reduced__. This aids the __interpretability__ of the plot and allows for __better insights.__ 


## <u> 7-day growth rate of cases </u>

```{r growthrateplot,fig.cap="Growth rate of cases within the analysis period",fig.align='center'}

date_interval <- interval(start = start_date,end = end_date)
df_growth_rate <- df %>%
  filter(diagnosis_date %within% date_interval) %>% #Restrict to the second wave
  group_by(diagnosis_date) %>%
  summarise(n=n()) %>%
  mutate(
    growth_rate=slider::slide_dbl(
      .x = n,
.f = function(v) {
log(v[7]/v[1]) / 7 #Seven-day growth rate
      },
      .before=8, #Only look into the past
      .after = 0
) )

pl3 <- ggplot(data=df_growth_rate,aes(x=diagnosis_date,y=growth_rate)) +
  geom_line() + theme_clean() +
  labs(x = "Diagnosis date", y = "Logarithmic growth rate") +
  ggtitle("7-day growth rate of cases \n in 2020") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.title = element_text(face = 'bold')) + geom_smooth(color='darkgreen') +
    annotate("segment",x = local_ld,
    xend = local_ld,y = -0.1,
    yend = 0.3,colour = "red",
    linetype = 1,size = 2) +
  annotate("segment",x = local_ld - days(6),
    y = 0.3,xend = local_ld ,
    yend = 0.25 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = local_ld - days(15),y = 0.32,
    colour = "black",label = 'Lockdowns implemented \n from 30/06/2020',size = unit(3, "pt")) +
  annotate("segment",x = face_mask,xend = face_mask,
    y = -0.1,yend = 0.3,colour = "blue",linetype = 1,size = 2) +
  annotate("segment",x = face_mask - days(6),y = 0.3,
    xend = face_mask ,yend = 0.25 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = face_mask - days(12),y = 0.33,colour = "black",
    label = 'Mandatory facemasks \n from 27/07/2020',
    size = unit(3, "pt"))

  
pl3
```



Based on the 7-day growth rate of cases in 2020 as depicted by figure \@ref(fig:growthrateplot), following are the key observations:

- There was a __rising trend of cases__ between the start of the analysis period to the first intervention (lockdown implementation from `r local_ld`).
- After the implementation of the first intervention which are the local lockdowns from `r local_ld`, there was a __drop in the growth rate observed__.
- After the implementation of the second intervention which is the mandatory facemasks from `r face_mask`, soon after the __growth rate dropped below 0__ as a result of which, the __overall positive cases started to drop__.

## <u> Relation between growth rate and effective transmission number </u>


### Part A

The growth rate $g$ and the effective transmission number $R(t)$ are very closely related to each other. To understand this relation, we can interpret $R(t)$ by its statistical effect on the population. The effective transmission number $R(t)$ indicates that __on average, how many people may be infected when an infectious person comes in contact with them__.

- For __$R(t)$ > 1__, on average, each infectious person infects more than one person __leading to an exponential growth of cases__.\
- For __$R(t)$ = 1__, on average, each infectious person infects one person. __Under such a circumstance, the daily cases start stagnating and flattening.__ \
- For __$R(t)$ < 1__, on average, each infectious person infects less than one person __leading to an exponential drop of cases__. \

The value of $R(t)$ can be __significantly altered through interventions such as lockdowns, facemasks and vaccinations__. Hence, the growth rate of cases are accordingly observed to rise or fall with the change in $R(t)$.


### Part B {#label1}

The relation between the __growth rate__ $g$ and the __effective transmission number__ $R(t)$ in the given equation is dependent on each other through the __average infectious period__ $T$. This equation gives us an estimation of the growth rate of cases.

The important thresholds which allow us to understand the current state of the disease are as follows :

- If __$g > 0$__, the epidemic undergoes an __exponential rise in daily cases__. \
- If __$g = 0$__, the number of cases start __stagnating and the daily case plot starts flattening__. \
- If __$g < 0$__, the epidemic undergoes an __exponential drop in daily cases__. \

On the other hand, the relation between the growth rate $g$ and the effective transmission number $R(t)$ as observed in class gives us an __estimate of the effective transmission number $R(t)$__. The equation is based on the assumption that there is no variance in the generation time(or average infectious period). The same equation based on the nomenclature provided here can be written as follows. 

$$\boxed{R(t) =  e^{gT}}$$ 

The thresholds for the above equation are as follows:

- For __$R(t)$ > 1__, on average, each infectious person infects more than one person __leading to an exponential growth of cases__.\
- For __$R(t)$ = 1__, on average, each infectious person infects one person. __Under such a circumstance, the daily cases start stagnating and flattening.__ \
- For __$R(t)$ < 1__, on average, each infectious person infects less than one person __leading to an exponential drop of cases__. \

## <u> Infectious disease modeling using the S.E.I.R. model </u>

### Population compartmentalization

In epidemiology, an infectious disease maybe modeled by a set of specific assumptions and the result of ordinary differential equations. These models are termed as compartmental models as they are used to divide the entire population into specific compartments. \

In any infectious disease modeling, it is extremely important to __estimate the delay of infection notification__. Based on the study by @lauer2020qifang , __the incubation period__, which is the delay between the inoculation (contact with virus) and symptoms is __approximately 5 days__. Additionally, based on the information by the __Department of Health and Human Services (DHHS) Victoria__, it may [take around 1-3 days](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjJl7bM7Jz_AhUngFYBHTBvAHQQFnoECAkQAw&url=https%3A%2F%2Fwww.dhhs.vic.gov.au%2Ftesting-coronavirus-english-accessible%23%3A~%3Atext%3DHow%2520long%2520does%2520it%2520take%2Chospital%2520where%2520you%2520got%2520tested.&usg=AOvVaw2RTE4ImgWjp0s3mWv-RXjN) to get an outcome of the result.

As a result, a close estimation of the delay in notification of a positive case can significantly aid the accurate modeling of the infectious disease. The S.E.I.R model attempts to do so by compartmentalizing the total population into the following four groups :

- __S (Symptomatic)__ : Susceptible people, those who can be infected. \
- __E (Exposed)__ : Individuals who are infected but not infectious at the moment. \
- __I (Infection)__ : Infected and infectious people, those who have got and can spread the virus. \
- __R (Recovered)__ : People who have recovered and cannot infect further. Consequently, they don't participate in the dynamics any further. \


### Intervention incorporation in the S.E.I.R. model

Using the S.E.I.R. model, the reproduction number, $R(o)$ helps us understand the average number of secondary infections produced by a typical infectious individual __in a completely susceptible population__. The threshold for $R(o)$ and $R_{eff}$ provide us similar insights which have been delineated in section \@ref(label1).

In order to understand how the value of $R(o)$ changes for various interventions, we can divide the time period of analysis into the following segments:

- Phase 1 : __No intervention period__ from `r start_date` to `r local_ld`.
- Phase 2 : __Initial intervention (Lockdowns)__ from `r local_ld` to `r face_mask`
- Phase 3 : __Additional intervention (Lockdowns + Facemasks)__ from `r face_mask` to `r end_date`.

To understand the effect of the interventions on the spread of the disease, the value of $\beta$ will be altered to account for the reduction of cases in __each of above timeline phases__. The exact steps involved in the incorporation of the interventions within the current S.E.I.R. model have been delineated in section \@ref(label2).



```{r interventions1, eval=FALSE}

initial_infected <- 20
initial_state <- c("S" = N - initial_infected, "E" = 0, "I" = initial_infected, "R" = 0, "incidence" = 0)
COVID_withemergency <- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    N <- S + E + I + R 

    if ((t > 29) | (t<=56)) {# First intervention
      beta <- beta * emergency_efficacy
    }
    
      if (t > 56) { # Second intervention
      beta <- beta * emergency_efficacy * 0.9
    }

    dSdt <- -beta * S * I / N
    dEdt <- beta * S * I / N - sigma * E
    dIdt <- sigma * E - gamma * I
    dRdt <- gamma * I
    dIncidencedt <- sigma * E
    return(list(
      c(dSdt, dEdt, dIdt, dRdt, dIncidencedt)
    ))
  })
}

```



### Ordinary Differential Equation for solving the model 


```{r tidy-model}

tidy_model <- function(ode_output, start_date) {
  as_tibble(ode_output) %>%
    mutate(
      date = as.Date(start_date + days(time)),
      daily_incidence = c(0, diff(incidence))
    )
}


solve_times <- seq(int_start(date_interval), int_end(date_interval), by = "1 day")


```




```{r logit, ,echo=FALSE}
logit <- function(x) {
  return(log(x / (1 - x)))
}

# And its inverse
inverse.logit <- function(x) {
  return(exp(x) / (1 + exp(x)))
}

```




### Initial parameter selection and solution {#label2}

Following are the initial guess parameters to be applied to the model:

- __$\beta = \frac36$__ \
- __$\sigma = \frac1{10}$__ \
- __$\gamma = \frac13$__ \
- __Initial infected cases = 20__


```{r initialize}
start_date <- ymd("2020/06/01") #Start date of analysis
end_date <- ymd("2020/09/13") #End date of analysis
local_ld <- ymd("2020/06/30") #Local lockdown initiates
face_mask <- ymd("2020/07/27") # Mandatory facemasks

date_interval <- interval(start_date, end_date)

df_sum <- df %>% filter (diagnosis_date %within% plot_interval) %>%  group_by(diagnosis_date) %>% summarise(Total_case_count =  sum(Total_case_count))

N <- sum(df_sum$Total_case_count)

```

In order to incorporate the effect of the interventions into the model, the $\beta$ value is altered for each intervention phase. As the disease infectiousness is majorly captured by the value of $\beta$, hence, __its value is changed for each of the two interventions to closely influence the number of predicted cases__. 

 - For $t < 29$, Phase 1 with no intervention period is observed. \
 - For $t > 29$, Phase 2 intervention (Local lockdown) period is observed. \
 - For $t > 56$, Phase 3 intervention (Face mask) period is observed. \
 
 Where $t$ represents the number of days since the start of the analysis.


```{r interventions, echo=FALSE}

initial_infected <- 20
initial_state <- c("S" = N - initial_infected, "E" = 0, "I" = initial_infected, "R" = 0, "incidence" = 0)
COVID_withemergency <- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    N <- S + E + I + R 

    if ((t > 29) | (t<=56)) {# First intervention
      beta <- beta * emergency_efficacy
    }
    
      if (t > 56) { # Second intervention
      beta <- beta * emergency_efficacy * 0.9
    }

    dSdt <- -beta * S * I / N
    dEdt <- beta * S * I / N - sigma * E
    dIdt <- sigma * E - gamma * I
    dRdt <- gamma * I
    dIncidencedt <- sigma * E
    return(list(
      c(dSdt, dEdt, dIdt, dRdt, dIncidencedt)
    ))
  })
}

```




```{r neg-log_rep, echo=FALSE}
negative_log_likelihood_emergency <- function(transformed_parameters, data, state, times, func, other_parameters) {

  beta <- exp(transformed_parameters["R0"]) * other_parameters["gamma"]
  names(beta) <- "beta"
  emergency_efficacy <- inverse.logit(transformed_parameters["emergency_efficacy"])
  names(emergency_efficacy) <- "emergency_efficacy"
  parameters <- c(beta, emergency_efficacy, other_parameters)
  out_ode <- ode(
    y = state,
    times = as.numeric(difftime(times, times[1], units = "days")),
    func = func,
    parms = parameters
  ) %>%
    tidy_model(start_date = times[1])
  -sum(dpois(
    x = data$Total_case_count[-1],
    lambda = out_ode$daily_incidence[-1],
    log = TRUE
  ))
}

```






```{r odeoutput}


initial_transformed_parameters <- c("R0" = log(2), "emergency_efficacy" = logit(0.5))
parameters <- c("gamma" = 1 / 6, "sigma" = 1 / 5)
optimum_mle <- optim(
  par = initial_transformed_parameters,
  fn = negative_log_likelihood_emergency,
  data = df_sum,
  state = initial_state,
  times = solve_times,
  func = COVID_withemergency,
  other_parameters = c(parameters["gamma"], parameters["sigma"])
)
optimal_parameters_R0 <- c(
  exp(optimum_mle$par["R0"]) * parameters["gamma"],
  inverse.logit(optimum_mle$par["emergency_efficacy"]),
  parameters["gamma"],
  parameters["sigma"]
)
names(optimal_parameters_R0)[1] <- "beta"



optimal_solution <- ode(
  y = initial_state,
  times = as.numeric(difftime(solve_times, solve_times[1], units = "days")),
  func = COVID_withemergency,
  parms = optimal_parameters_R0
) %>%
  tidy_model(start_date = solve_times[1])



head(optimal_solution) %>%
kable(caption = 'ODE output',booktabs = TRUE) %>% 
  kable_styling(bootstrap_options = c("bordered","hover")) %>%
  row_spec(0,background="rgb(172,175,145)",color='black',font_size = 18,align = 'c')


```







```{r eval=TRUE}


optimal_parameters_R0 <- c(
  exp(optimum_mle$par["R0"]) * parameters["gamma"],
  inverse.logit(optimum_mle$par["emergency_efficacy"]),
  parameters["gamma"],
  parameters["sigma"]
)
names(optimal_parameters_R0)[1] <- "beta"

initial_transformed_parameters <- c("R0" = log(2), "emergency_efficacy" = logit(0.5))
parameters <- c("gamma" = 1/10, "sigma" = 1 / 3)
optimum_mle <- optim(
  par = initial_transformed_parameters,
  fn = negative_log_likelihood_emergency,
  data = df_sum,
  state = initial_state,
  times = solve_times,
  func = COVID_withemergency,
  other_parameters = c(parameters["gamma"], parameters["sigma"])
)
```







Based on the above initial parameters, the following code-chunk contains the solution of the ordinary differential equation to calculate the predicted number of diagnosed cases. Table \@ref(tab:odeoutput) lists out the initial rows of the output datafram while figure \@ref(fig:fitact) depicts the comparison between the actual number of cases and the modeled number of cases using the S.E.I.R. model with the initial chosen parameters. 




## <u> Implementatation of maximum likelihood function </u>

The likelihood function allows us to understand that __given a set of initial parameters, how likely would the model output parameters match with the actual cases__. Alternatively, we can interpret the result of the likelihood function as __the probability that the actual values are within a distribution of our model output__.


### Fixed and Estimated parameters

In this model, following are the parameters that are __fixed__:

- __Population of Victoria__ is assumed to remain constant during the course of the analysis. \
- An __initial number of cases__ which helps the model create a baseline estimation. \
- __Disease-specific parameters__: Specific parameters are obtained directly from literature studies. For example, the incubation period, infectious period, or transmission rate for a particular disease may be fixed based on existing research. As a result, the coefficient $\sigma$, which corresponds to the __corresponds to the inverse of the average incubation period__ of the disease can be fixed.
- __Time-period for recovery__ of a person after being infected maybe considered to be constant and not change over time. Hence, $\gamma$ can be considered to be a fixed parameter.

In this model, following are the parameters that are to be __estimated__:

- Initial parameters such as the values of the susceptible (S), exposed (E), infected (I) and recovered (R) fractions of the population.
- Transmission parameter $\beta$,which represents the transmission rate or the average number of secondary infections caused by an infected individual per unit of time will be estimated as this value can change with interventions applied.
- Consequently, the value of growth reproduction number $R(o)$ as it is the ratio $\frac\beta{\gamma}$


### Poisson likelihood function

The maximum likelihood function using the Poisson likelihood method is applied to the current model, which is shown through the code chunk below:


```{r neg-log}
negative_log_likelihood_emergency <- function(transformed_parameters, data, state, times, func, other_parameters) {
 
  beta <- exp(transformed_parameters["R0"]) * other_parameters["gamma"]
  names(beta) <- "beta"
  emergency_efficacy <- inverse.logit(transformed_parameters["emergency_efficacy"])
  names(emergency_efficacy) <- "emergency_efficacy"
  parameters <- c(beta, emergency_efficacy, other_parameters)
  out_ode <- ode(
    y = state,
    times = as.numeric(difftime(times, times[1], units = "days")),
    func = func,
    parms = parameters
  ) %>%
    tidy_model(start_date = times[1])
  -sum(dpois(
    x = data$Total_case_count[-1],
    lambda = out_ode$daily_incidence[-1],
    log = TRUE
  ))
}

```




```{r fitact, fig.cap="Comparison of modeled and actual cases with interventions",fig.align='center'}

pl4 <- ggplot() +
  geom_col(
    aes(x = diagnosis_date, y = Total_case_count),
    width = 1, fill = "skyblue", colour = "blue",
    data = df_sum %>% filter (diagnosis_date %within% date_interval)
  ) +
  geom_point(
    aes(x = date, y = daily_incidence),
    data = optimal_solution
  ) +
    annotate("segment",x = local_ld,
    xend = local_ld,y = 0,
    yend = 700,colour = "red",
    linetype = 1,size = 2) +
  annotate("segment",x = local_ld - days(6),
    y = 500,xend = local_ld ,
    yend = 480 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = local_ld - days(15),y = 520,
    colour = "black",label = 'Lockdowns implemented \n from 30/06/2020',size = unit(3, "pt")) +
  annotate("segment",x = face_mask,xend = face_mask,
    y = 0,yend = 700,colour = "darkgreen",linetype = 1,size = 2) +
  annotate("segment",x = face_mask - days(6),y = 500,
    xend = face_mask ,yend = 480 ,arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
  annotate("text",x = face_mask - days(12),y = 530,colour = "black",
    label = 'Mandatory facemasks \n from 27/07/2020',
    size = unit(3, "pt")) +
  annotate("text",x = local_ld - days(25),y = 650,colour = "black",
    label = 'Phase 1 \n No interventions',
    size = unit(3, "pt")) +
  annotate("text",x = local_ld + days(15),y = 650,colour = "black",
    label = 'Phase 2 \n Lockdowns applied',
    size = unit(3, "pt")) +
   annotate("text",x = face_mask + days(25),y = 650,colour = "black",
    label = 'Phase 3 \n Mandatory facemasks',
    size = unit(3, "pt")) +
  labs(x="Diagnosis date",y='Number of cases') + 
  ggtitle("Comparison of modeled and actual cases with interventions \n in Victoria ") + theme_clean() + theme(plot.title = element_text(hjust = 0.5)) 

pl4
```

Based on the estimated incidences  after utilising the Poisson's likelihood function and comparing it against the actual number of cases as illustrated by figure \@ref(fig:fitact), we can observe the following :

- The estimated number of __cases closely follow__ the actual number of cases.
- The rise in the number of estimated cases were __observed to dip__ with each of the interventions. This scenario closely depicts the actual fall in the number of cases.
- Due to the interventions, the infection rate is expected to drop through a change in the $\beta$ value. This has been accounted for in the model as a result of which, __cases have dropped further after the second intervention__.
- While the peak number of cases were not accurately estimated, the __timing of the peak was however fairly accurate__.

### Limitations of the current study

Following are the limitations of the current analysis:

- The current methodology is based on the S.E.I.R. model which greatly simplifies the disease dynamics by __considering the entire population as a well-mixed homogeneous group__.
- While the S.E.I.R. model provides an extra level of granularity and detail in the analysis when compared to the S.I.R. model, it also has two additional drawbacks : __the unknown incubation period and the initial fraction of infected population__. 
- Unknown parameters such as the __incubation period, initial infected population, recovery period are conveniently assumed__ for the current analysis. However, in a complex dynamic scenario, these values maybe expected to change with time.
- In order to model the effect of the interventions, the infection rate was manually altered by manipulating the value of $\beta$ for each intervention period in order for the estimated cases to match with the actual cases. Hence, the current model lacks an __explicit way to incorporate the effect of interventions__.
- The accuracy and reliability of S.E.I.R. model predictions heavily depend on __the availability and quality of data used for parameter estimation__. Incomplete or limited data may cause the model to significantly deviate from the actual solution.



# üìâ Data curation

Following are the key data curation considerations for the current COVID-19 dataset:

- __Date format__: The variable name "diagnosis_date" containing the dates have been formatted in the __YYYY-MM-DD__ format which is ideal for spreadsheet consumption.
- __No empty cells__: The dataset __does not contain any empty cells or null values__.
- __One item per cell__: Each cell in the dataset contains one single item.
- __Data as rectangle__: The data is organised as a single rectangle. Each row contains the number of cases for a particular date while each column contains the variables in the dataset.
- __Data dictionary__: The data dictionary for the current dataset can be __found within the "data" folder__.
- __No calculations in raw data__: There are no calculations in the dataset. The current dataset contains observational data.
- __No font color or highlighting__: The dataset is a CSV file and has __no associated font color or cell highlighting__.
- __Good names__: The dataset contains variables and observations which are __appropriately named__ for easy understanding.
- __Backups__: The current dataset is hosted on the Victorian Government website for COVID-19. Additionally, this dataset maybe stored in cloud storages such as GitHub to create additional copies which can be easily accessed at a later point.
- __Data validation to avoid data entry errors__: Data can be validated by using the count function in R for comparing the number of cases for each day and whether it adds up to the actual reported number of cases. This would help account for ant possible data entry errors in the dataset.
- __Save data in plain text__: While the original dataset is not in the plain text format, an additional copy of the COVID-19 dataset has been saved in the ".txt" format and __maybe found in the "data" folder__.


# Resources

Following resources and libraries were used for conducting the above analysis:

- __RStudio__ : RStudio Team (2020), Integrated Development for R. RStudio, PBC, Boston, MA URL http://www.rstudio.com/.

- __Tidyverse__ : Wickham H, Averick M, Bryan J, Chang W, McGowan LD, Fran√ßois R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, M√ºller K,
  Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). ‚ÄúWelcome to the tidyverse.‚Äù _Journal of Open Source Software_,
  *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.
  
- __ggplot2__ : H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.

- __Lubridate__ : Garrett Grolemund, Hadley Wickham (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25. URL
  https://www.jstatsoft.org/v40/i03/.
  
- __here__ : M√ºller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, <https://CRAN.R-project.org/package=here>.

- __ggthemes__ : Arnold J (2021). _ggthemes: Extra Themes, Scales and Geoms for 'ggplot2'_. R package version 4.2.4, <https://CRAN.R-project.org/package=ggthemes>.

- __bookdown__ : Xie Y (2023). _bookdown: Authoring Books and Technical Documents with R Markdown_. R package version 0.33, <https://github.com/rstudio/bookdown>.

- __stringr__ : Wickham H (2022). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.0, <https://CRAN.R-project.org/package=stringr>.

- __DT__ : Xie Y, Cheng J, Tan X (2023). _DT: A Wrapper of the JavaScript Library 'DataTables'_. R package version 0.27, <https://CRAN.R-project.org/package=DT>.

- __deSolve__ : Karline Soetaert, Thomas Petzoldt, R. Woodrow Setzer (2010). Solving Differential Equations in R: Package deSolve. Journal of Statistical Software, 33(9),
  1--25. doi:10.18637/jss.v033.i09
  
- __kableExtra__ : Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.3.4, <https://CRAN.R-project.org/package=kableExtra>.

# References

